{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8943e395-7814-4c37-b62d-61e79a4f162e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# from datasets import combined_brain_1mm, combined_brain_17mm\n",
    "from generative.metrics import MultiScaleSSIMMetric\n",
    "from generative.networks.nets import AutoencoderKL, DiffusionModelUNet\n",
    "from generative.networks.schedulers import DDPMScheduler\n",
    "from models.autoencoderkl import AutoencoderKLDownsampleControl\n",
    "from monai.config import print_config\n",
    "from monai.utils import set_determinism\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58763b68-9d20-4c3b-803e-113a10dfbd05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_cond_diffusion_model(diffusion_root_path, ckpt):\n",
    "    diffusion_root_path = Path(diffusion_root_path)\n",
    "    diffusion_config_path = diffusion_root_path / \"config.yaml\"\n",
    "    diffusion_ckpt_path = diffusion_root_path / ckpt\n",
    "    print(f\"Diffusion path {diffusion_ckpt_path}\")\n",
    "\n",
    "    config = OmegaConf.load(diffusion_config_path)\n",
    "    diffusion_model = DiffusionModelUNet(**config[\"ldm\"].get(\"params\", dict()))\n",
    "    scheduler = DDPMScheduler(**config[\"ldm\"].get(\"scheduler\", dict()))\n",
    "    diffusion_ckpt = torch.load(diffusion_ckpt_path)\n",
    "\n",
    "    diffusion_model = torch.nn.DataParallel(diffusion_model)\n",
    "    # diffusion_model.load_state_dict(diffusion_ckpt[\"diffusion\"])\n",
    "    diffusion_model.load_state_dict(diffusion_ckpt[\"diffusion\"])\n",
    "\n",
    "    checkpoint_name = str(diffusion_ckpt_path).split(\"/\")[-1]\n",
    "\n",
    "    return diffusion_model, scheduler, checkpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d8a20-0f24-428e-b9fd-e2c1656ef6e6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion path /home/sz9jt/data/generative_brain/cond_diffusion/diffusion_tomshcp3d_cond/checkpoint100.pth\n",
      "using checkpoint100.pth\n",
      "If using patch:  False\n",
      "[256, 320, 256]\n",
      "(80, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:49<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:49<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:49<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:49<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:49<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:49<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:50<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 1000/1000 [02:49<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 1, 1, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████▉             | 565/1000 [01:36<01:13,  5.88it/s]"
     ]
    }
   ],
   "source": [
    "# sample with conditional image from test dataset\n",
    "device = torch.device(\"cuda\")\n",
    "root_path = \"/home/sz9jt/data/generative_brain/cond_diffusion/diffusion_tomshcp3d_cond\"\n",
    "diffusion_model, scheduler, ckptname = get_cond_diffusion_model(root_path, \"checkpoint100.pth\")\n",
    "print(f\"using {ckptname}\")\n",
    "diffusion_model.eval()\n",
    "diffusion_model.to(device)\n",
    "\n",
    "config = OmegaConf.load(root_path + \"/config.yaml\")\n",
    "ds_params = config.dataset.params\n",
    "ds_params[\"type\"] = \"test\"\n",
    "ds_params[\"patch_size\"] = (224, 288, 224)\n",
    "test_ds = datasets.hcp_3d.TomsHCP3DCondPatchDataset(**ds_params)\n",
    "print(\"If using patch: \", test_ds.patch)\n",
    "\n",
    "data = test_ds[-3]\n",
    "gt_img = data[\"gt_image\"].squeeze()\n",
    "cond_img = data[\"cond_image\"].squeeze()\n",
    "\n",
    "# first convert data shape into factors of 64\n",
    "data_shape = [224, 288, 224]\n",
    "factors = []\n",
    "for item in data_shape:\n",
    "    factors.append((int(item // 64) + 1) * 64)\n",
    "print(factors)\n",
    "\n",
    "tmp = np.zeros(factors) - 1\n",
    "tmp[:224, :288, :224] = gt_img\n",
    "gt_img = tmp\n",
    "\n",
    "tmp = np.zeros(factors) - 1\n",
    "tmp[:224, :288, :224] = cond_img\n",
    "cond_img = tmp\n",
    "\n",
    "all_gt_patches = []\n",
    "all_cond_patches = []\n",
    "\n",
    "for x in range(0, factors[0], 64):\n",
    "    for y in range(0, factors[1], 64):\n",
    "        for z in range(0, factors[2], 64):\n",
    "            all_gt_patches.append(gt_img[x : x + 64, y : y + 64, z : z + 64])\n",
    "            all_cond_patches.append(cond_img[x : x + 64, y : y + 64, z : z + 64])\n",
    "\n",
    "all_gt_patches = np.array(all_gt_patches).reshape(-1, 1, 64, 64, 64)\n",
    "all_cond_patches = np.array(all_cond_patches).reshape(-1, 1, 64, 64, 64)\n",
    "\n",
    "print(all_cond_patches.shape)\n",
    "\n",
    "torch.manual_seed(config.args.seed)\n",
    "\n",
    "batch_size = 1\n",
    "all_res_patches = []\n",
    "for i in range(4, len(all_gt_patches), batch_size):\n",
    "    end_idx = min(i + batch_size, len(all_gt_patches))\n",
    "    batch_len = end_idx - i\n",
    "\n",
    "    cond = torch.from_numpy(all_cond_patches[i:end_idx]).float().to(device)\n",
    "    y = torch.randn(cond.shape).to(device)\n",
    "    with torch.no_grad():\n",
    "        prompt_embeds = None\n",
    "        for t in tqdm(scheduler.timesteps, ncols=70):\n",
    "            tmp_input = torch.cat([y, cond], dim=1).float().to(device)\n",
    "            noise_pred = diffusion_model(x=tmp_input, timesteps=torch.asarray((t,)).to(device), context=prompt_embeds)\n",
    "            y, _ = scheduler.step(noise_pred, t, y)\n",
    "    all_res_patches.append(y.cpu().numpy())\n",
    "    np.save(\"res.npy\", np.array(all_res_patches))\n",
    "    print(np.array(all_res_patches).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "020e15d8-7993-4067-9ed4-e36b58cb11dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion path /home/sz9jt/data/generative_brain/cond_diffusion/diffusion_tomshcp3d_cond/checkpoint100.pth\n",
      "using checkpoint100.pth\n",
      "All data: 1113\n",
      "Dataset size: 223\n",
      "If using patch:  False\n",
      "[256, 320, 256]\n"
     ]
    }
   ],
   "source": [
    "# sample with conditional image from test dataset\n",
    "device = torch.device(\"cuda\")\n",
    "root_path = \"/home/sz9jt/data/generative_brain/cond_diffusion/diffusion_tomshcp3d_cond\"\n",
    "diffusion_model, scheduler, ckptname = get_cond_diffusion_model(root_path, \"checkpoint100.pth\")\n",
    "print(f\"using {ckptname}\")\n",
    "diffusion_model.eval()\n",
    "diffusion_model.to(device)\n",
    "\n",
    "config = OmegaConf.load(root_path + \"/config.yaml\")\n",
    "ds_params = config.dataset.params\n",
    "ds_params[\"type\"] = \"test\"\n",
    "ds_params[\"patch_size\"] = (224, 288, 224)\n",
    "test_ds = datasets.hcp_3d.TomsHCP3DCondPatchDataset(**ds_params)\n",
    "print(\"If using patch: \", test_ds.patch)\n",
    "\n",
    "data = test_ds[-3]\n",
    "gt_img = data[\"gt_image\"].squeeze()\n",
    "cond_img = data[\"cond_image\"].squeeze()\n",
    "\n",
    "# first convert data shape into factors of 64\n",
    "data_shape = [224, 288, 224]\n",
    "factors = []\n",
    "for item in data_shape:\n",
    "    factors.append((int(item // 64) + 1) * 64)\n",
    "print(factors)\n",
    "\n",
    "tmp = np.zeros(factors) - 1\n",
    "tmp[:224, :288, :224] = gt_img\n",
    "gt_img = tmp\n",
    "\n",
    "tmp = np.zeros(factors) - 1\n",
    "tmp[:224, :288, :224] = cond_img\n",
    "cond_img = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e4d551f-4161-4e2e-9d6c-28fe519d69d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 64, 64, 64) (76, 1, 1, 64, 64, 64)\n",
      "(80, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "tmp1 = np.load(\"tmp.npy\")\n",
    "tmp2 = np.load(\"res.npy\")\n",
    "\n",
    "print(tmp1.shape, tmp2.shape)\n",
    "\n",
    "tmp = np.concatenate([tmp1.squeeze(), tmp2.squeeze()])\n",
    "print(tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b756ab78-be5d-4ace-9ca4-a65b4670cbf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 320, 256)\n"
     ]
    }
   ],
   "source": [
    "print(gt_img.shape)\n",
    "\n",
    "output_img = np.zeros(gt_img.shape) - 1\n",
    "\n",
    "idx = 0\n",
    "for x in range(0, factors[0], 64):\n",
    "    for y in range(0, factors[1], 64):\n",
    "        for z in range(0, factors[2], 64):\n",
    "            output_img[x : x + 64, y : y + 64, z : z + 64] = tmp[idx]\n",
    "            idx += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd0c94b0-ed12-4a45-94fe-0993ff201f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 288, 224)\n"
     ]
    }
   ],
   "source": [
    "gt_img = data[\"gt_image\"].squeeze()\n",
    "print(gt_img.shape)\n",
    "cond_img = data[\"cond_image\"].squeeze()\n",
    "\n",
    "outptu_img = output_img[:224, :288, :224]\n",
    "\n",
    "tmp = nib.Nifti1Image(gt_img, np.eye(4))\n",
    "nib.save(tmp, \"gt_img.nii.gz\")\n",
    "\n",
    "tmp = nib.Nifti1Image(cond_img, np.eye(4))\n",
    "nib.save(tmp, \"cond_img.nii.gz\")\n",
    "\n",
    "tmp = nib.Nifti1Image(output_img, np.eye(4))\n",
    "nib.save(tmp, \"output_img.nii.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrinr",
   "language": "python",
   "name": "mrinr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
